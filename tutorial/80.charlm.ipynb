{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Character based RNN language model\n",
    "(c) Deniz Yuret, 2019. Based on http://karpathy.github.io/2015/05/21/rnn-effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Objectives: Learn to define and train a character based language model and generate text from it. Minibatch blocks of text. Keep a persistent RNN state between updates. Train a Shakespeare generator and a Julia programmer using the same type of model.\n",
    "* Prerequisites: [RNN basics](60.rnn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display width, load packages, import symbols\n",
    "ENV[\"COLUMNS\"]=72\n",
    "using Pkg; haskey(Pkg.installed(),\"Knet\") || Pkg.add(\"Knet\")\n",
    "using Statistics: mean\n",
    "using Knet: Knet, AutoGrad, Data, param, param0, RNN, dropout, value, nll, adam, progress!, minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed; w; end\n",
    "\n",
    "Embed(vocab::Int,embed::Int)=Embed(param(embed,vocab))\n",
    "\n",
    "(e::Embed)(x) = e.w[:,x]  # (B,T)->(X,B,T)->rnn->(H,B,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Linear; w; b; end\n",
    "\n",
    "Linear(input::Int, output::Int)=Linear(param(output,input), param0(output))\n",
    "\n",
    "mat(x) = reshape(x, size(x,1), :)     # (H,B,T)->(H,B*T)\n",
    "\n",
    "(l::Linear)(x) = l.w * mat(x) .+ l.b  # (H,B,T)->(V,B*T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a chain of layers\n",
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "(c::Chain)(x,y) = nll(c(x),y)\n",
    "(c::Chain)(d::Data) = mean(c(x,y) for (x,y) in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The h=0,c=0 options to RNN enable a persistent state between iterations\n",
    "CharLM(vocab::Int,embed::Int,hidden::Int; o...) = \n",
    "    Chain(Embed(vocab,embed), RNN(embed,hidden;h=0,c=0,o...), Linear(hidden,vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# To generate text from trained models\n",
    "function generate(model,chars,n)\n",
    "    function sample(y)\n",
    "        p = Array(exp.(y)); r = rand()*sum(p)\n",
    "        for j=1:length(p); (r -= p[j]) < 0 && return j; end\n",
    "    end\n",
    "    x = 1\n",
    "    reset!(model)\n",
    "    for i=1:n\n",
    "        y = model([x])\n",
    "        x = sample(y)\n",
    "        print(chars[x])\n",
    "    end\n",
    "    println()\n",
    "end\n",
    "\n",
    "reset!(m::Chain)=(for r in m.layers; r isa RNN && (r.c=r.h=0); end);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running experiments\n",
    "function trainresults(file,model,chars)\n",
    "    if (print(\"Train from scratch? \"); readline()[1]=='y')\n",
    "        progress!(adam(model,repeat(dtrn,EPOCHS)), interval=1.0)\n",
    "        Knet.save(file,\"model\",model,\"chars\",chars)\n",
    "    else\n",
    "        isfile(file) || download(\"http://people.csail.mit.edu/deniz/models/tutorial/$file\",file)\n",
    "        model,chars = Knet.load(file,\"model\",\"chars\")\n",
    "    end\n",
    "    Knet.gc() # To save gpu memory\n",
    "    return model,chars\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Complete Works of William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "RNNTYPE = :lstm\n",
    "BATCHSIZE = 256\n",
    "SEQLENGTH = 100\n",
    "INPUTSIZE = 168\n",
    "VOCABSIZE = 84\n",
    "HIDDENSIZE = 334\n",
    "NUMLAYERS = 1\n",
    "EPOCHS = 30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load 'The Complete Works of William Shakespeare'\n",
    "include(Knet.dir(\"data\",\"gutenberg.jl\"))\n",
    "trn,tst,chars = shakespeare()\n",
    "map(summary,(trn,tst,chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Print a sample\n",
    "println(string(chars[trn[1020:1210]]...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Minibatch data\n",
    "function mb(a)\n",
    "    N = length(a) ÷ BATCHSIZE\n",
    "    x = reshape(a[1:N*BATCHSIZE],N,BATCHSIZE)' # reshape full data to (B,N) with contiguous rows\n",
    "    minibatch(x[:,1:N-1], x[:,2:N], SEQLENGTH) # split into (B,T) blocks \n",
    "end\n",
    "dtrn,dtst = mb.((trn,tst))\n",
    "length.((dtrn,dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.(first(dtrn))  # each x and y have dimensions (BATCHSIZE,SEQLENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.17e+00  100.00%┣█████████████████████┫ 5760/5760 [06:23/06:23, 15.04/s]\n",
    "shakemodel,shakechars = trainresults(\"shakespeare113.jld2\", \n",
    "    CharLM(VOCABSIZE, INPUTSIZE, HIDDENSIZE; rnnType=RNNTYPE, numLayers=NUMLAYERS), chars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(shakemodel(dtst))  # Perplexity = 3.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "generate(shakemodel,shakechars,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia programmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNTYPE = :lstm\n",
    "BATCHSIZE = 64\n",
    "SEQLENGTH = 64\n",
    "INPUTSIZE = 512\n",
    "VOCABSIZE = 128\n",
    "HIDDENSIZE = 512\n",
    "NUMLAYERS = 2\n",
    "EPOCHS = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read julia base library source code\n",
    "base = joinpath(Sys.BINDIR, Base.DATAROOTDIR, \"julia\")\n",
    "text = \"\"\n",
    "for (root,dirs,files) in walkdir(base)\n",
    "    for f in files\n",
    "        f[end-2:end] == \".jl\" || continue\n",
    "        text *= read(joinpath(root,f), String)\n",
    "    end\n",
    "    # println((root,length(files),all(f->contains(f,\".jl\"),files)))\n",
    "end\n",
    "length(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique chars, sort by frequency, assign integer ids.\n",
    "charcnt = Dict{Char,Int}()\n",
    "for c in text; charcnt[c]=1+get(charcnt,c,0); end\n",
    "chars = sort(collect(keys(charcnt)), by=(x->charcnt[x]), rev=true)\n",
    "charid = Dict{Char,Int}()\n",
    "for i=1:length(chars); charid[chars[i]]=i; end\n",
    "hcat(chars, map(c->charcnt[c],chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only VOCABSIZE most frequent chars, split into train and test\n",
    "data = map(c->charid[c], collect(text))\n",
    "data[data .> VOCABSIZE] .= VOCABSIZE\n",
    "ntst = 1<<19\n",
    "tst = data[1:ntst]\n",
    "trn = data[1+ntst:end]\n",
    "length.((data,trn,tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample\n",
    "r = rand(1:(length(trn)-1000))\n",
    "println(string(chars[trn[r:r+1000]]...)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatch data\n",
    "function mb(a)\n",
    "    N = length(a) ÷ BATCHSIZE\n",
    "    x = reshape(a[1:N*BATCHSIZE],N,BATCHSIZE)' # reshape full data to (B,N) with contiguous rows\n",
    "    minibatch(x[:,1:N-1], x[:,2:N], SEQLENGTH) # split into (B,T) blocks \n",
    "end\n",
    "dtrn,dtst = mb.((trn,tst))\n",
    "length.((dtrn,dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.(first(dtrn))  # each x and y have dimensions (BATCHSIZE,SEQLENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.50e-01  100.00%┣██████████████████▉┫ 21100/21100 [18:00/18:00, 19.53/s]\n",
    "juliamodel,juliachars = trainresults(\"juliacharlm113.jld2\", \n",
    "    CharLM(VOCABSIZE, INPUTSIZE, HIDDENSIZE; rnnType=RNNTYPE, numLayers=NUMLAYERS),chars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(juliamodel(dtst))  # Perplexity = 3.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(juliamodel,juliachars,1000)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "julia.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
