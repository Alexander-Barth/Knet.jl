{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Plots, JLD, NBInclude\n",
    "nbinclude(\"mnist.ipynb\")  # loads MNIST, defines dtrn,dtst,Atype,train,softmax,zeroone\n",
    "mlpdata = load(\"mlp.jld\") # loads MLP results for comparison\n",
    "ENV[\"COLUMNS\"]=80         # column width for array printing\n",
    "plotlyjs();               # for interactive plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "conv4(w, x; kwargs...)\n",
       "```\n",
       "\n",
       "Execute convolutions or cross-correlations using filters specified with `w` over tensor `x`.\n",
       "\n",
       "Currently KnetArray{Float32/64,4/5} and Array{Float32/64,4} are supported as `w` and `x`.  If `w` has dimensions `(W1,W2,...,I,O)` and `x` has dimensions `(X1,X2,...,I,N)`, the result `y` will have dimensions `(Y1,Y2,...,O,N)` where\n",
       "\n",
       "```\n",
       "Yi=1+floor((Xi+2*padding[i]-Wi)/stride[i])\n",
       "```\n",
       "\n",
       "Here `I` is the number of input channels, `O` is the number of output channels, `N` is the number of instances, and `Wi,Xi,Yi` are spatial dimensions.  `padding` and `stride` are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "# Keywords\n",
       "\n",
       "  * `padding=0`: the number of extra zeros implicitly concatenated at the start and at the end of each dimension.\n",
       "  * `stride=1`: the number of elements to slide to reach the next filtering window.\n",
       "  * `upscale=1`: upscale factor for each dimension.\n",
       "  * `mode=0`: 0 for convolution and 1 for cross-correlation.\n",
       "  * `alpha=1`: can be used to scale the result.\n",
       "  * `handle`: handle to a previously created cuDNN context. Defaults to a Knet allocated handle.\n"
      ],
      "text/plain": [
       "```\n",
       "conv4(w, x; kwargs...)\n",
       "```\n",
       "\n",
       "Execute convolutions or cross-correlations using filters specified with `w` over tensor `x`.\n",
       "\n",
       "Currently KnetArray{Float32/64,4/5} and Array{Float32/64,4} are supported as `w` and `x`.  If `w` has dimensions `(W1,W2,...,I,O)` and `x` has dimensions `(X1,X2,...,I,N)`, the result `y` will have dimensions `(Y1,Y2,...,O,N)` where\n",
       "\n",
       "```\n",
       "Yi=1+floor((Xi+2*padding[i]-Wi)/stride[i])\n",
       "```\n",
       "\n",
       "Here `I` is the number of input channels, `O` is the number of output channels, `N` is the number of instances, and `Wi,Xi,Yi` are spatial dimensions.  `padding` and `stride` are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "# Keywords\n",
       "\n",
       "  * `padding=0`: the number of extra zeros implicitly concatenated at the start and at the end of each dimension.\n",
       "  * `stride=1`: the number of elements to slide to reach the next filtering window.\n",
       "  * `upscale=1`: upscale factor for each dimension.\n",
       "  * `mode=0`: 0 for convolution and 1 for cross-correlation.\n",
       "  * `alpha=1`: can be used to scale the result.\n",
       "  * `handle`: handle to a previously created cuDNN context. Defaults to a Knet allocated handle.\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution operator in Knet\n",
    "@doc conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = reshape([1.0, 2.0, 3.0], (3, 1, 1, 1)) = [1.0; 2.0; 3.0]\n",
      "x = reshape([1.0:7.0...], (7, 1, 1, 1)) = [1.0; 2.0; 3.0; 4.0; 5.0; 6.0; 7.0]\n",
      "y = conv4(w, x) = [10.0; 16.0; 22.0; 28.0; 34.0]\n"
     ]
    }
   ],
   "source": [
    "# Convolution in 1-D\n",
    "@show w = reshape([1.0,2.0,3.0], (3,1,1,1))\n",
    "@show x = reshape([1.0:7.0...], (7,1,1,1))\n",
    "@show y = conv4(w, x);  # size Y = X - W + 1 = 5 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y2 = conv4(w, x, padding=(1, 0)) = [4.0; 10.0; 16.0; 22.0; 28.0; 34.0; 32.0]\n"
     ]
    }
   ],
   "source": [
    "# Padding\n",
    "@show y2 = conv4(w, x, padding=(1,0));  # size Y = X + 2P - W + 1 = 7 with padding=1\n",
    "# To preserve input size (Y=X) for a given W, what padding P should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y3 = conv4(w, x; padding=(1, 0), stride=3) = [4.0; 22.0; 32.0]\n"
     ]
    }
   ],
   "source": [
    "# Stride\n",
    "@show y3 = conv4(w, x; padding=(1,0), stride=3);  # size Y = 1 + floor((X+2P-W)/S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y4 = conv4(w, x, mode=0) = [10.0; 16.0; 22.0; 28.0; 34.0]\n",
      "y5 = conv4(w, x, mode=1) = [14.0; 20.0; 26.0; 32.0; 38.0]\n"
     ]
    }
   ],
   "source": [
    "# Mode\n",
    "@show y4 = conv4(w, x, mode=0);  # Default mode (convolution) inverts w\n",
    "@show y5 = conv4(w, x, mode=1);  # mode=1 (cross-correlation) does not invert w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3×1×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0  4.0  7.0\n",
       " 2.0  5.0  8.0\n",
       " 3.0  6.0  9.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution in more dimensions\n",
    "x = reshape([1.0:9.0...], (3,3,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2×1×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0  3.0\n",
       " 2.0  4.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = reshape([1.0:4.0...], (2,2,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2×1×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 23.0  53.0\n",
       " 33.0  63.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = conv4(w, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3×2×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0  4.0  7.0\n",
       " 2.0  5.0  8.0\n",
       " 3.0  6.0  9.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 10.0  13.0  16.0\n",
       " 11.0  14.0  17.0\n",
       " 12.0  15.0  18.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution with multiple channels, filters, and instances\n",
    "# size X = [X1,X2,...,Xd,Cx,N] where d is the number of dimensions, Cx is channels, N is instances\n",
    "x = reshape([1.0:18.0...], (3,3,2,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size W = [W1,W2,...,Wd,Cx,Cy] where d is the number of dimensions, Cx is input channels, Cy is output channels\n",
    "w = reshape([1.0:24.0...], (2,2,2,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2×3×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 328.0  436.0\n",
       " 364.0  472.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 808.0  1108.0\n",
       " 908.0  1208.0\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 1288.0  1780.0\n",
       " 1452.0  1944.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size Y = [Y1,Y2,...,Yd,Cy,N]  where Yi = 1 + floor((Xi+2Pi-Wi)/Si), Cy is channels, N is instances\n",
    "y = conv4(w,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://cs231n.github.io/assets/conv-demo/index.html for an animated example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "pool(x; kwargs...)\n",
       "```\n",
       "\n",
       "Compute pooling of input values (i.e., the maximum or average of several adjacent values) to produce an output with smaller height and/or width.\n",
       "\n",
       "Currently 4 or 5 dimensional KnetArrays with `Float32` or `Float64` entries are supported.  If `x` has dimensions `(X1,X2,...,I,N)`, the result `y` will have dimensions `(Y1,Y2,...,I,N)` where\n",
       "\n",
       "```\n",
       "Yi=1+floor((Xi+2*padding[i]-window[i])/stride[i])\n",
       "```\n",
       "\n",
       "Here `I` is the number of input channels, `N` is the number of instances, and `Xi,Yi` are spatial dimensions.  `window`, `padding` and `stride` are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "# Keywords:\n",
       "\n",
       "  * `window=2`: the pooling window size for each dimension.\n",
       "  * `padding=0`: the number of extra zeros implicitly concatenated at the start and at the end of each dimension.\n",
       "  * `stride=window`: the number of elements to slide to reach the next pooling window.\n",
       "  * `mode=0`: 0 for max, 1 for average including padded values, 2 for average excluding padded values.\n",
       "  * `maxpoolingNanOpt=0`: Nan numbers are not propagated if 0, they are propagated if 1.\n",
       "  * `alpha=1`: can be used to scale the result.\n",
       "  * `handle`: Handle to a previously created cuDNN context. Defaults to a Knet allocated handle.\n"
      ],
      "text/plain": [
       "```\n",
       "pool(x; kwargs...)\n",
       "```\n",
       "\n",
       "Compute pooling of input values (i.e., the maximum or average of several adjacent values) to produce an output with smaller height and/or width.\n",
       "\n",
       "Currently 4 or 5 dimensional KnetArrays with `Float32` or `Float64` entries are supported.  If `x` has dimensions `(X1,X2,...,I,N)`, the result `y` will have dimensions `(Y1,Y2,...,I,N)` where\n",
       "\n",
       "```\n",
       "Yi=1+floor((Xi+2*padding[i]-window[i])/stride[i])\n",
       "```\n",
       "\n",
       "Here `I` is the number of input channels, `N` is the number of instances, and `Xi,Yi` are spatial dimensions.  `window`, `padding` and `stride` are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "# Keywords:\n",
       "\n",
       "  * `window=2`: the pooling window size for each dimension.\n",
       "  * `padding=0`: the number of extra zeros implicitly concatenated at the start and at the end of each dimension.\n",
       "  * `stride=window`: the number of elements to slide to reach the next pooling window.\n",
       "  * `mode=0`: 0 for max, 1 for average including padded values, 2 for average excluding padded values.\n",
       "  * `maxpoolingNanOpt=0`: Nan numbers are not propagated if 0, they are propagated if 1.\n",
       "  * `alpha=1`: can be used to scale the result.\n",
       "  * `handle`: Handle to a previously created cuDNN context. Defaults to a Knet allocated handle.\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pooling operator in Knet\n",
    "@doc pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = reshape([1.0:6.0...], (6, 1, 1, 1)) = [1.0; 2.0; 3.0; 4.0; 5.0; 6.0]\n",
      "pool(x) = [2.0; 4.0; 6.0]\n"
     ]
    }
   ],
   "source": [
    "# 1-D pooling example\n",
    "@show x = reshape([1.0:6.0...], (6,1,1,1))\n",
    "@show pool(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool(x; window=3) = [3.0; 6.0]\n"
     ]
    }
   ],
   "source": [
    "# Window size\n",
    "@show pool(x; window=3);  # size Y = floor(X/W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool(x; padding=(1, 0)) = [1.0; 3.0; 5.0; 6.0]\n"
     ]
    }
   ],
   "source": [
    "# Padding\n",
    "@show pool(x; padding=(1,0));  # size Y = floor((X+2P)/W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = reshape([1.0:10.0...], (10, 1, 1, 1)) = [1.0; 2.0; 3.0; 4.0; 5.0; 6.0; 7.0; 8.0; 9.0; 10.0]\n",
      "pool(x; stride=4) = [2.0; 6.0; 10.0]\n"
     ]
    }
   ],
   "source": [
    "# Stride\n",
    "@show x = reshape([1.0:10.0...], (10,1,1,1));\n",
    "@show pool(x; stride=4);  # size Y = 1 + floor((X+2P-W)/S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array(x) = [1.0; 2.0; 3.0; 4.0; 5.0; 6.0]\n",
      "Array(pool(x; padding=(1, 0), mode=0)) = [1.0; 3.0; 5.0; 6.0]\n",
      "Array(pool(x; padding=(1, 0), mode=1)) = [0.5; 2.5; 4.5; 3.0]\n",
      "Array(pool(x; padding=(1, 0), mode=2)) = [1.0; 2.5; 4.5; 6.0]\n"
     ]
    }
   ],
   "source": [
    "# Mode\n",
    "x = ka(reshape([1.0:6.0...], (6,1,1,1)))\n",
    "@show Array(x)\n",
    "@show Array(pool(x; padding=(1,0), mode=0))  # max pooling\n",
    "@show Array(pool(x; padding=(1,0), mode=1))  # avg pooling\n",
    "@show Array(pool(x; padding=(1,0), mode=2)); # avg pooling excluding padded values (is not implemented on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4×1×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0  5.0   9.0  13.0\n",
       " 2.0  6.0  10.0  14.0\n",
       " 3.0  7.0  11.0  15.0\n",
       " 4.0  8.0  12.0  16.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More dimensions\n",
    "x = reshape([1.0:16.0...], (4,4,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2×1×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 6.0  14.0\n",
       " 8.0  16.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4×2×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0  5.0   9.0  13.0\n",
       " 2.0  6.0  10.0  14.0\n",
       " 3.0  7.0  11.0  15.0\n",
       " 4.0  8.0  12.0  16.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 17.0  21.0  25.0  29.0\n",
       " 18.0  22.0  26.0  30.0\n",
       " 19.0  23.0  27.0  31.0\n",
       " 20.0  24.0  28.0  32.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple channels and instances\n",
    "x = reshape([1.0:32.0...], (4,4,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2×2×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 6.0  14.0\n",
       " 8.0  16.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 22.0  30.0\n",
       " 24.0  32.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each channel and each instance is pooled separately\n",
    "pool(x)  # size Y = (Y1,...,Yd,Cx,N) where Yi are spatial dims, Cx and N are identical to input X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A convolutional neural network model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function convnet(w,x; pdrop=(0,0,0))    # pdrop[1]:input, pdrop[2]:conv, pdrop[3]:fc\n",
    "    for i=1:2:length(w)\n",
    "        if ndims(w[i]) == 4     # convolutional layer\n",
    "            x = dropout(x, pdrop[i==1?1:2])\n",
    "            x = conv4(w[i],x) .+ w[i+1]\n",
    "            x = pool(relu.(x))\n",
    "        elseif ndims(w[i]) == 2 # fully connected layer\n",
    "            x = dropout(x, pdrop[i==1?1:3])\n",
    "            x = w[i]*mat(x) .+ w[i+1]\n",
    "            if i < length(w)-1; x = relu.(x); end\n",
    "        else\n",
    "            error(\"Unknown layer type: $(size(w[i]))\")\n",
    "        end\n",
    "    end\n",
    "    return x\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initialization for multiple layers\n",
    "# h[i] is an integer for a fully connected layer, a triple of integers for convolution filters\n",
    "# Output is an array [w0,b0,w1,b1,...,wn,bn] where wi,bi is the weight matrix/tensor and bias vector for the i'th layer\n",
    "function cinit(h...)  # use cinit(x,h1,h2,...,hn,y) for n hidden layer model\n",
    "    w = Any[]\n",
    "    x = h[1]\n",
    "    for i=2:length(h)\n",
    "        if isa(h[i],Tuple)\n",
    "            (x1,x2,cx) = x\n",
    "            (w1,w2,cy) = h[i]\n",
    "            push!(w, xavier(w1,w2,cx,cy))\n",
    "            push!(w, zeros(1,1,cy,1))\n",
    "            x = (div(x1-w1+1,2),div(x2-w2+1,2),cy) # assuming conv4 with p=0, s=1 and pool with p=0,w=s=2\n",
    "        elseif isa(h[i],Integer)\n",
    "            push!(w, xavier(h[i],prod(x)))\n",
    "            push!(w, zeros(h[i],1))\n",
    "            x = h[i]\n",
    "        else\n",
    "            error(\"Unknown layer type: $(h[i])\")\n",
    "        end\n",
    "    end\n",
    "    map(Atype, w)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Knet.KnetArray{Float32,N} where N,1}:\n",
       " Knet.KnetArray{Float32,4}(Knet.KnetPtr(Ptr{Void} @0x00000081055e0000, 2000, 0, nothing), (5, 5, 1, 20))   \n",
       " Knet.KnetArray{Float32,4}(Knet.KnetPtr(Ptr{Void} @0x00000081052e0e00, 80, 0, nothing), (1, 1, 20, 1))     \n",
       " Knet.KnetArray{Float32,4}(Knet.KnetPtr(Ptr{Void} @0x00000081056e0000, 100000, 0, nothing), (5, 5, 20, 50))\n",
       " Knet.KnetArray{Float32,4}(Knet.KnetPtr(Ptr{Void} @0x00000081052e1000, 200, 0, nothing), (1, 1, 50, 1))    \n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Void} @0x00000081057e0000, 1600000, 0, nothing), (500, 800))   \n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Void} @0x00000081055e0800, 2000, 0, nothing), (500, 1))        \n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Void} @0x00000081054e8000, 20000, 0, nothing), (10, 500))      \n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Void} @0x00000081052e1200, 40, 0, nothing), (10, 1))           "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet=cinit((28,28,1), (5,5,20), (5,5,50), 500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2925642f0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x,y) = first(dtst)\n",
    "softmax(lenet,x,y,convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.017571094f0, 0.0046000000000000485)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if !isfile(\"cnn.jld\")\n",
    "    setseed(1)\n",
    "    lenet=cinit((28,28,1), (5,5,20), (5,5,50), 500, 10)\n",
    "    @time weights=train(lenet,dtrn,convnet,lr=0.1,pdrop=(0,0,0.3)) # 233.8s\n",
    "    @time trnloss = [ softmax(w,dtrn,convnet) for w in weights ]   # 85.4s\n",
    "    @time tstloss = [ softmax(w,dtst,convnet) for w in weights ]   # 14.3s\n",
    "    @time trnerr = [ zeroone(w,dtrn,convnet) for w in weights ]    # 84.9s\n",
    "    @time tsterr = [ zeroone(w,dtst,convnet) for w in weights ]    # 14.1s\n",
    "    @save \"cnn.jld\" trnloss tstloss trnerr tsterr\n",
    "else    \n",
    "    @eval (@load \"cnn.jld\")\n",
    "end\n",
    "minimum(tstloss),minimum(tsterr)  # 0.0176, 0.0046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([mlpdata[\"trnloss\"] mlpdata[\"tstloss\"] trnloss tstloss],ylim=(0.0,0.1),\n",
    "    labels=[:trnMLP :tstMLP :trnCNN :tstCNN],xlabel=\"Epochs\",ylabel=\"Loss\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot([mlpdata[\"trnerr\"] mlpdata[\"tsterr\"] trnerr tsterr],ylim=(0.0,0.03),\n",
    "    labels=[:trnMLP :tstMLP :trnCNN :tstCNN],xlabel=\"Epochs\",ylabel=\"Error\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution vs Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = reshape([1.0, 2.0, 3.0], (3, 1, 1, 1)) = [1.0; 2.0; 3.0]\n",
      "x = reshape([1.0:7.0...], (7, 1, 1, 1)) = [1.0; 2.0; 3.0; 4.0; 5.0; 6.0; 7.0]\n",
      "y = conv4(w, x) = [10.0; 16.0; 22.0; 28.0; 34.0]\n"
     ]
    }
   ],
   "source": [
    "# Convolution and matrix multiplication can be implemented in terms of each other.\n",
    "# Convolutional networks have no additional representational power, only statistical efficiency.\n",
    "# Our original 1-D example\n",
    "@show w = reshape([1.0,2.0,3.0], (3,1,1,1))\n",
    "@show x = reshape([1.0:7.0...], (7,1,1,1))\n",
    "@show y = conv4(w, x);  # size Y = X - W + 1 = 5 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×7 Array{Float64,2}:\n",
       " 3.0  2.0  1.0  0.0  0.0  0.0  0.0\n",
       " 0.0  3.0  2.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  3.0  2.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  3.0  2.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0  3.0  2.0  1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution as matrix multiplication (1)\n",
    "# Turn w into a (Y,X) sparse matrix\n",
    "w2 = Float64[3 2 1 0 0 0 0; 0 3 2 1 0 0 0; 0 0 3 2 1 0 0; 0 0 0 3 2 1 0; 0 0 0 0 3 2 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y2 = w2 * mat(x) = [10.0; 16.0; 22.0; 28.0; 34.0]\n"
     ]
    }
   ],
   "source": [
    "@show y2 = w2 * mat(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×5 Array{Float64,2}:\n",
       " 1.0  2.0  3.0  4.0  5.0\n",
       " 2.0  3.0  4.0  5.0  6.0\n",
       " 3.0  4.0  5.0  6.0  7.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution as matrix multiplication (2)\n",
    "# Turn x into a (W,Y) dense matrix (aka the im2col operation)\n",
    "# This is used to speed up convolution with known efficient matmul algorithms\n",
    "x3 = Float64[1 2 3 4 5; 2 3 4 5 6; 3 4 5 6 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w3 = [3.0 2.0 1.0] = [3.0 2.0 1.0]\n",
      "y3 = w3 * x3 = [10.0 16.0 22.0 28.0 34.0]\n"
     ]
    }
   ],
   "source": [
    "@show w3 = [3.0 2.0 1.0]\n",
    "@show y3 = w3 * x3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Array{Float64,2}:\n",
       " 1.0  3.0  5.0\n",
       " 2.0  4.0  6.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication as convolution\n",
    "# This could be used to make a fully connected network accept variable sized inputs.\n",
    "w = reshape([1.0:6.0...], (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×1 Array{Float64,2}:\n",
       " 1.0\n",
       " 2.0\n",
       " 3.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = reshape([1.0:3.0...], (3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×1 Array{Float64,2}:\n",
       " 22.0\n",
       " 28.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×1×1×2 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0\n",
       " 3.0\n",
       " 5.0\n",
       "\n",
       "[:, :, 1, 2] =\n",
       " 2.0\n",
       " 4.0\n",
       " 6.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider w with size (Y,X)\n",
    "# Treat each of the Y rows of w as a convolution filter\n",
    "w2 = reshape(Array(w)', (3,1,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×1×1×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0\n",
       " 2.0\n",
       " 3.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape x for convolution\n",
    "x2 = reshape(x, (3,1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1×2×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 22.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 28.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use conv4 for matrix multiplication\n",
    "y2 = conv4(w2, x2; mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So there is no difference between the class of functions representable with an MLP vs CNN.\n",
    "# Sparse connections and weight sharing give CNNs more generalization power with images.\n",
    "# Number of parameters in MLP256: (256x784)+256+(10x256)+10 = 203530\n",
    "# Number of parameters in LeNet: (5*5*1*20)+20+(5*5*20*50)+50+(500*800)+500+(10*500)+10 = 431080"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
