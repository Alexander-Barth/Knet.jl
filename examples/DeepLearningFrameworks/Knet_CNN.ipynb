{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knet CNN Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After installing and starting Julia run the following to install the required packages:\n",
    "# Pkg.init(); Pkg.update()\n",
    "# for p in (\"CUDAdrv\",\"IJulia\",\"Knet\"); Pkg.add(p); end\n",
    "# Pkg.checkout(\"Knet\",\"ilkarman\") # make sure we have the right Knet version\n",
    "# Pkg.build(\"Knet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /kuacc/users/dyuret/.julia/compiled/v1.0/Knet/f4vSz.ji for Knet [1902f260-5fb4-5aff-8c31-6271790ab950]\n",
      "└ @ Base loading.jl:1184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu() = 0\n"
     ]
    }
   ],
   "source": [
    "using Knet; @show gpu()\n",
    "True=true # so we can read the python params\n",
    "include(\"common/params.py\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Linux\n",
      "Julia: 1.0.0\n",
      "GPU: Tesla K80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(\"OS: \", Sys.KERNEL)\n",
    "println(\"Julia: \", VERSION)\n",
    "#println(\"Knet: \", Pkg.installed(\"Knet\"))\n",
    "println(\"GPU: \", read(`nvidia-smi --query-gpu=name --format=csv,noheader`,String))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "function initmodel(; atype=KnetArray, dtype=Float32, winit=xavier, binit=zeros)\n",
    "    w(dims...)=atype(winit(dtype,dims...))\n",
    "    b(dims...)=atype(binit(dtype,dims...))\n",
    "    return Any[\n",
    "        w(3,3,3,50), b(1,1,50,1),\n",
    "        w(3,3,50,50), b(1,1,50,1),\n",
    "        w(3,3,50,100), b(1,1,100,1),\n",
    "        w(3,3,100,100), b(1,1,100,1),\n",
    "        w(512,6400), b(512,1),\n",
    "        w(10,512), b(10,1)\n",
    "    ]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and its gradient\n",
    "function predict(w,x)\n",
    "    convbias(x,w,b) = conv4(w,x;padding=1) .+ b\n",
    "    fc(x,w,b) = w * mat(x) .+ b;\n",
    "    x = relu.(convbias(x,w[1],w[2]))\n",
    "    x = relu.(pool(convbias(x,w[3],w[4])))\n",
    "    x = dropout(x,0.25)\n",
    "    x = relu.(convbias(x,w[5],w[6]))\n",
    "    x = relu.(pool(convbias(x,w[7],w[8])))\n",
    "    x = dropout(x,0.25)\n",
    "    x = relu.(fc(x,w[9],w[10]))\n",
    "    x = dropout(x,0.5)\n",
    "    return fc(x,w[11],w[12])\n",
    "end\n",
    "\n",
    "loss(w,x,y)=nll(predict(w,x),y) # nll: negative log likelihood\n",
    "lossgradient = grad(loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Reading cifar-10-binary.tar.gz...\n",
      "└ @ Main /kuacc/users/dyuret/.julia/dev/Knet/data/cifar.jl:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.030743 seconds (2.94 M allocations: 1.859 GiB, 22.35% gc time)\n",
      "32×32×3×50000 Array{Float32,4}\n",
      "50000-element Array{UInt8,1}\n",
      "32×32×3×10000 Array{Float32,4}\n",
      "10000-element Array{UInt8,1}\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "include(Knet.dir(\"data\",\"cifar.jl\"))\n",
    "@time (xtrn,ytrn,xtst,ytst,lbls)=cifar10()\n",
    "for d in (xtrn,ytrn,xtst,ytst); println(summary(d)); end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for training\n",
    "model = optim = nothing; Knet.gc() # Clear memory from last run\n",
    "model = initmodel()\n",
    "optim = optimizers(model, Momentum; lr=LR, gamma=MOMENTUM);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26.533408 seconds (23.48 M allocations: 1.719 GiB, 6.96% gc time)\n"
     ]
    }
   ],
   "source": [
    "# cold start\n",
    "@time for (x,y) in minibatch(xtrn,ytrn,BATCHSIZE;shuffle=true,xtype=KnetArray)\n",
    "    grads = lossgradient(model, x, y)\n",
    "    update!(model, grads, optim)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for training\n",
    "model = optim = nothing; Knet.gc() # Clear memory from last run\n",
    "model = initmodel()\n",
    "optim = optimizers(model, Momentum; lr=LR, gamma=MOMENTUM);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training...\n",
      "└ @ Main In[10]:2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14.097721 seconds (1.76 M allocations: 661.696 MiB, 0.39% gc time)\n",
      " 13.765463 seconds (1.76 M allocations: 661.564 MiB, 0.45% gc time)\n",
      " 13.776932 seconds (1.76 M allocations: 661.564 MiB, 0.39% gc time)\n",
      " 13.786659 seconds (1.76 M allocations: 661.564 MiB, 0.39% gc time)\n",
      " 13.795239 seconds (1.76 M allocations: 661.564 MiB, 0.43% gc time)\n",
      " 13.788541 seconds (1.76 M allocations: 661.564 MiB, 0.41% gc time)\n",
      " 13.786247 seconds (1.76 M allocations: 661.564 MiB, 0.39% gc time)\n",
      " 13.792936 seconds (1.76 M allocations: 661.564 MiB, 0.38% gc time)\n",
      " 13.815097 seconds (1.76 M allocations: 661.564 MiB, 0.44% gc time)\n",
      " 13.790948 seconds (1.76 M allocations: 661.564 MiB, 0.42% gc time)\n",
      "138.201485 seconds (17.61 M allocations: 6.461 GiB, 0.41% gc time)\n"
     ]
    }
   ],
   "source": [
    "# 159s\n",
    "@info(\"Training...\")\n",
    "@time for epoch in 1:EPOCHS\n",
    "    @time for (x,y) in minibatch(xtrn,ytrn,BATCHSIZE;shuffle=true,xtype=KnetArray)\n",
    "        grads = lossgradient(model, x, y)\n",
    "        update!(model, grads, optim)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.703879 seconds (1.60 M allocations: 195.873 MiB, 2.31% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7270633012820513"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy 77.54\n",
    "testdata = minibatch(xtst,ytst,BATCHSIZE;xtype=KnetArray)\n",
    "@time accuracy(model,testdata,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
