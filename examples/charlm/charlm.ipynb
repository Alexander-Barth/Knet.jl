{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character based RNN language model trained on 'The Complete Works of William Shakespeare'\n",
    "Based on http://karpathy.github.io/2015/05/21/rnn-effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNTYPE = :lstm\n",
    "BATCHSIZE = 256\n",
    "SEQLENGTH = 100\n",
    "INPUTSIZE = 168\n",
    "VOCABSIZE = 84\n",
    "HIDDENSIZE = 334\n",
    "NUMLAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "LR=0.001\n",
    "BETA_1=0.9\n",
    "BETA_2=0.999\n",
    "EPS=1e-08\n",
    "EPOCHS = 30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"4934845-element Array{UInt8,1}\", \"526731-element Array{UInt8,1}\", \"84-element Array{Char,1}\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 'The Complete Works of William Shakespeare'\n",
    "using Knet\n",
    "include(Knet.dir(\"data\",\"gutenberg.jl\"))\n",
    "trn,tst,chars = shakespeare()\n",
    "map(summary,(trn,tst,chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "    Cheated of feature by dissembling nature,\r\n",
      "    Deform'd, unfinish'd, sent before my time\r\n",
      "    Into this breathing world scarce half made up,\r\n",
      "    And that so lamely and unfashionable\r\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Print a sample\n",
    "println(string(chars[trn[1020:1210]]...)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minibatch data\n",
    "function mb(a)\n",
    "    N = div(length(a),BATCHSIZE)\n",
    "    x = reshape(a[1:N*BATCHSIZE],N,BATCHSIZE)' # reshape full data to (B,N) with contiguous rows\n",
    "    minibatch(x[:,1:N-1], x[:,2:N], SEQLENGTH) # split into (B,T) blocks \n",
    "end\n",
    "dtrn,dtst = mb(trn),mb(tst)\n",
    "map(length, (dtrn,dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "function initmodel()\n",
    "    w(d...)=KnetArray(xavier(Float32,d...))\n",
    "    b(d...)=KnetArray(zeros(Float32,d...))\n",
    "    r,wr = rnninit(INPUTSIZE,HIDDENSIZE,rnnType=RNNTYPE,numLayers=NUMLAYERS,dropout=DROPOUT)\n",
    "    wx = w(INPUTSIZE,VOCABSIZE)\n",
    "    wy = w(VOCABSIZE,HIDDENSIZE)\n",
    "    by = b(VOCABSIZE,1)\n",
    "    return r,wr,wx,wy,by\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and its gradient\n",
    "function predict(ws,xs,hx,cx;pdrop=0)\n",
    "    r,wr,wx,wy,by = ws\n",
    "    x = wx[:,xs]                                    # xs=(B,T) x=(X,B,T)\n",
    "    x = dropout(x,pdrop)\n",
    "    y,hy,cy = rnnforw(r,wr,x,hx,cx,hy=true,cy=true) # y=(H,B,T) hy=cy=(H,B,L)\n",
    "    y = dropout(y,pdrop)\n",
    "    y2 = reshape(y,size(y,1),size(y,2)*size(y,3))   # y2=(H,B*T)\n",
    "    return wy*y2.+by, hy, cy\n",
    "end\n",
    "\n",
    "function loss(w,x,y,h;o...)\n",
    "    py,hy,cy = predict(w,x,h...;o...)\n",
    "    h[1],h[2] = getval(hy),getval(cy)\n",
    "    return nll(py,y)\n",
    "end\n",
    "\n",
    "lossgradient = gradloss(loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test loops\n",
    "function train(model,data,optim)\n",
    "    hiddens = Any[nothing,nothing]\n",
    "    Σ,N=0,0\n",
    "    for (x,y) in data\n",
    "        grads,loss1 = lossgradient(model,x,y,hiddens;pdrop=DROPOUT)\n",
    "        update!(model, grads, optim)\n",
    "        Σ,N=Σ+loss1,N+1\n",
    "    end\n",
    "    return Σ/N\n",
    "end\n",
    "\n",
    "function test(model,data)\n",
    "    hiddens = Any[nothing,nothing]\n",
    "    Σ,N=0,0\n",
    "    for (x,y) in data\n",
    "        Σ,N = Σ+loss(model,x,y,hiddens), N+1\n",
    "    end\n",
    "    return Σ/N\n",
    "end; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mTraining...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23.367439 seconds (2.11 M allocations: 233.286 MiB, 0.26% gc time)\n",
      "  0.986285 seconds (363.41 k allocations: 27.896 MiB, 0.43% gc time)\n",
      "(:epoch, 1, :trnppl, 17.207191f0, :tstppl, 8.8799925f0)\n",
      " 17.668259 seconds (232.09 k allocations: 131.532 MiB, 0.12% gc time)\n",
      "  0.570718 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 2, :trnppl, 7.401502f0, :tstppl, 6.533962f0)\n",
      " 17.757882 seconds (232.25 k allocations: 131.535 MiB, 0.08% gc time)\n",
      "  0.574279 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 3, :trnppl, 5.9158125f0, :tstppl, 5.6346264f0)\n",
      " 17.814497 seconds (233.28 k allocations: 131.550 MiB, 0.09% gc time)\n",
      "  0.583290 seconds (7.14 k allocations: 9.020 MiB, 0.36% gc time)\n",
      "(:epoch, 4, :trnppl, 5.2262263f0, :tstppl, 5.1046495f0)\n",
      " 17.897471 seconds (233.34 k allocations: 131.551 MiB, 0.07% gc time)\n",
      "  0.578130 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 5, :trnppl, 4.785228f0, :tstppl, 4.751793f0)\n",
      " 17.905744 seconds (233.21 k allocations: 131.550 MiB, 0.08% gc time)\n",
      "  0.579939 seconds (6.81 k allocations: 9.015 MiB, 0.36% gc time)\n",
      "(:epoch, 6, :trnppl, 4.473601f0, :tstppl, 4.498031f0)\n",
      " 17.938202 seconds (233.66 k allocations: 131.556 MiB, 0.09% gc time)\n",
      "  0.586103 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 7, :trnppl, 4.239677f0, :tstppl, 4.308611f0)\n",
      " 17.947238 seconds (233.28 k allocations: 131.550 MiB, 0.07% gc time)\n",
      "  0.583684 seconds (6.41 k allocations: 9.008 MiB, 0.34% gc time)\n",
      "(:epoch, 8, :trnppl, 4.064556f0, :tstppl, 4.1537704f0)\n",
      " 17.968095 seconds (234.07 k allocations: 131.562 MiB, 0.08% gc time)\n",
      "  0.582321 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 9, :trnppl, 3.9172251f0, :tstppl, 4.0415573f0)\n",
      " 17.937014 seconds (233.21 k allocations: 131.550 MiB, 0.08% gc time)\n",
      "  0.578992 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 10, :trnppl, 3.8037415f0, :tstppl, 3.951235f0)\n",
      " 17.930228 seconds (233.26 k allocations: 131.550 MiB, 0.07% gc time)\n",
      "  0.584203 seconds (6.94 k allocations: 9.017 MiB, 0.36% gc time)\n",
      "(:epoch, 11, :trnppl, 3.7133665f0, :tstppl, 3.8690042f0)\n",
      " 17.964018 seconds (233.54 k allocations: 131.554 MiB, 0.08% gc time)\n",
      "  0.581353 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 12, :trnppl, 3.6377268f0, :tstppl, 3.7953856f0)\n",
      " 17.940732 seconds (233.27 k allocations: 131.550 MiB, 0.08% gc time)\n",
      "  0.583801 seconds (6.55 k allocations: 9.011 MiB, 0.35% gc time)\n",
      "(:epoch, 13, :trnppl, 3.5704634f0, :tstppl, 3.7414238f0)\n",
      " 17.937662 seconds (233.94 k allocations: 131.560 MiB, 0.07% gc time)\n",
      "  0.577232 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 14, :trnppl, 3.5147889f0, :tstppl, 3.7011695f0)\n",
      " 17.931359 seconds (233.21 k allocations: 131.550 MiB, 0.08% gc time)\n",
      "  0.583442 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 15, :trnppl, 3.4656668f0, :tstppl, 3.658926f0)\n",
      " 17.933490 seconds (233.26 k allocations: 131.550 MiB, 0.07% gc time)\n",
      "  0.578805 seconds (7.08 k allocations: 9.019 MiB, 0.90% gc time)\n",
      "(:epoch, 16, :trnppl, 3.423523f0, :tstppl, 3.6220417f0)\n",
      " 17.954966 seconds (233.41 k allocations: 131.552 MiB, 0.07% gc time)\n",
      "  0.582789 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 17, :trnppl, 3.3856316f0, :tstppl, 3.6091304f0)\n",
      " 17.961568 seconds (233.27 k allocations: 131.550 MiB, 0.07% gc time)\n",
      "  0.590552 seconds (6.66 k allocations: 9.012 MiB, 0.35% gc time)\n",
      "(:epoch, 18, :trnppl, 3.3490443f0, :tstppl, 3.5778708f0)\n",
      " 17.932287 seconds (233.73 k allocations: 131.557 MiB, 0.08% gc time)\n",
      "  0.583383 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 19, :trnppl, 3.3185394f0, :tstppl, 3.5914545f0)\n",
      " 17.952158 seconds (233.28 k allocations: 131.550 MiB, 0.09% gc time)\n",
      "  0.576107 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 20, :trnppl, 3.2900393f0, :tstppl, 3.5333977f0)\n",
      " 17.921180 seconds (233.27 k allocations: 131.550 MiB, 0.07% gc time)\n",
      "  0.583438 seconds (7.21 k allocations: 9.021 MiB, 0.36% gc time)\n",
      "(:epoch, 21, :trnppl, 3.2637138f0, :tstppl, 3.546831f0)\n",
      " 17.944195 seconds (233.19 k allocations: 131.549 MiB, 0.08% gc time)\n",
      "  0.577509 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 22, :trnppl, 3.2402399f0, :tstppl, 3.5557911f0)\n",
      " 17.934116 seconds (233.28 k allocations: 131.550 MiB, 0.09% gc time)\n",
      "  0.578822 seconds (6.87 k allocations: 9.016 MiB, 0.36% gc time)\n",
      "(:epoch, 23, :trnppl, 3.2195306f0, :tstppl, 3.5611682f0)\n",
      " 17.932488 seconds (233.60 k allocations: 131.555 MiB, 0.07% gc time)\n",
      "  0.585111 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 24, :trnppl, 3.2000113f0, :tstppl, 3.5291839f0)\n",
      " 17.927224 seconds (233.21 k allocations: 131.550 MiB, 0.08% gc time)\n",
      "  0.583394 seconds (6.54 k allocations: 9.011 MiB, 0.35% gc time)\n",
      "(:epoch, 25, :trnppl, 3.1809583f0, :tstppl, 3.5117626f0)\n",
      " 17.930632 seconds (233.93 k allocations: 131.560 MiB, 0.09% gc time)\n",
      "  0.582545 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 26, :trnppl, 3.1632314f0, :tstppl, 3.502403f0)\n",
      " 18.111835 seconds (233.28 k allocations: 131.550 MiB, 0.07% gc time)\n",
      "  0.575568 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 27, :trnppl, 3.1469166f0, :tstppl, 3.4955883f0)\n",
      " 17.934111 seconds (233.27 k allocations: 131.550 MiB, 0.07% gc time)\n",
      "  0.585386 seconds (7.00 k allocations: 9.018 MiB, 0.59% gc time)\n",
      "(:epoch, 28, :trnppl, 3.1315691f0, :tstppl, 3.490243f0)\n",
      " 17.913955 seconds (233.41 k allocations: 131.553 MiB, 0.07% gc time)\n",
      "  0.579419 seconds (3.65 k allocations: 8.966 MiB)\n",
      "(:epoch, 29, :trnppl, 3.1172984f0, :tstppl, 3.4825473f0)\n",
      " 17.932895 seconds (233.26 k allocations: 131.550 MiB, 0.08% gc time)\n",
      "  0.585719 seconds (6.68 k allocations: 9.013 MiB, 0.36% gc time)\n",
      "(:epoch, 30, :trnppl, 3.1040323f0, :tstppl, 3.4801264f0)\n",
      "561.412387 seconds (9.52 M allocations: 4.242 GiB, 0.09% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Tuple{Knet.RNN,Knet.KnetArray{Float32,3},Knet.KnetArray{Float32,2},Knet.KnetArray{Float32,2},Knet.KnetArray{Float32,2}}\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model or load from file if exists\n",
    "using JLD\n",
    "model=optim=nothing; knetgc()\n",
    "if !isfile(\"shakespeare.jld\")\n",
    "    model = initmodel()\n",
    "    optim = optimizers(model, Adam; lr=LR, beta1=BETA_1, beta2=BETA_2, eps=EPS);    info(\"Training...\")\n",
    "    @time for epoch in 1:EPOCHS\n",
    "        @time trnloss = train(model,dtrn,optim) # ~18 seconds\n",
    "        @time tstloss = test(model,dtst)        # ~0.5 seconds\n",
    "        println((:epoch, epoch, :trnppl, exp(trnloss), :tstppl, exp(tstloss)))\n",
    "    end\n",
    "    save(\"shakespeare.jld\",\"model\",model)\n",
    "else\n",
    "    model = load(\"shakespeare.jld\",\"model\")\n",
    "end\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    And, how to had pass it rank'd!  \n",
      "    Upar it not.\n",
      "  VIRGILIA. I Winnob sailors. Hardle you, I welcome, my courage is.\n",
      "  BEDFORD. Mine us gellow grandament my hoarses-tit\n",
      "    No mock dogst perbertious; are the best lov'd;\n",
      "    Buffice this your childish effects and doings!\n",
      "    But if I beseech you, sir, be relents\n",
      "    I fear me.\n",
      "  MURTHERENE. Nay, forswore here is a bradger so. If I will not live,\n",
      "    Why, to take set fore sore of this offite the wife.\n",
      "  HORTENSIUS. Why, underthrew your husband, thou speaks for comfort\n",
      "    And seems my nature confederates: 'tis twain to\n",
      "    First obly he'll not forswore.              Untellias Marcius.\n",
      "    But what's I with many wishest childre Petrac's need?\n",
      "                    Our moets that come from Troy.                      \n",
      "                   Altur's maidy sweet,\n",
      "      Enfirs, 'tis but thy wounds to in my love.\n",
      "            Which, line of my good Queen,\n",
      "           And, truest as like against night;\n",
      "    The sack find liet rea\n"
     ]
    }
   ],
   "source": [
    "# Sample from trained model\n",
    "function generate(model,n)\n",
    "    function sample(y)\n",
    "        p,r=Array(exp.(y-logsumexp(y))),rand()\n",
    "        for j=1:length(p); (r -= p[j]) < 0 && return j; end\n",
    "    end\n",
    "    h,c = nothing,nothing\n",
    "    x = findfirst(chars,'\\n')\n",
    "    for i=1:n\n",
    "        y,h,c = predict(model,[x],h,c)\n",
    "        x = sample(y)\n",
    "        print(chars[x])\n",
    "    end\n",
    "    println()\n",
    "end\n",
    "\n",
    "generate(model,1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
